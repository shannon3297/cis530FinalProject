{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import string\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (3,4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_feats = pd.read_csv('train-dev-test/train_cleaned_features.csv', delimiter=',', encoding=\"utf-8\")\n",
    "dev_feats = pd.read_csv('train-dev-test/dev_cleaned_features.csv', delimiter=',', encoding=\"utf-8\")\n",
    "test_feats = pd.read_csv('train-dev-test/test_cleaned_features.csv', delimiter=',', encoding=\"utf-8\")\n",
    "\n",
    "# Clear whitespace\n",
    "train_feats.columns = train_feats.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old length:  3515562\n",
      "New length:  3515538\n"
     ]
    }
   ],
   "source": [
    "# Dropping stuff!\n",
    "\n",
    "# Drop all rows where time is NA?\n",
    "print(\"Old length: \", len(train_feats))\n",
    "train_feats = train_feats[train_feats['time'].notna()]\n",
    "print(\"New length: \", len(train_feats))\n",
    "\n",
    "# Just drop hashtags for now, too difficult for M3 to deal with\n",
    "train_feats = train_feats.drop(['hashtags'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>place</th>\n",
       "      <th>user_location</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>...</th>\n",
       "      <th>num_present</th>\n",
       "      <th>trump_present</th>\n",
       "      <th>hashtag_present</th>\n",
       "      <th>covid</th>\n",
       "      <th>vaccine</th>\n",
       "      <th>profanity_present</th>\n",
       "      <th>emoji_present</th>\n",
       "      <th>url_present</th>\n",
       "      <th>question_exclamation_present</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pretty much any corona virus germ that wants t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PG County</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Thu</td>\n",
       "      <td>Mar</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19:52:15</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @RealSaavedra: Good.\\n\\nIt came from China.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sydney, New South Wales</td>\n",
       "      <td>394</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>Mar</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19:52:15</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @nicolebyer: Everyone in this looks sick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ferrets</td>\n",
       "      <td>695</td>\n",
       "      <td>48499</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>Mar</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19:52:15</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @jabinbotsford: Close up of President @real...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>30492</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>Mar</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19:52:15</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Biancaixvi: Corona day 3: it just feels li...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Huntley, IL</td>\n",
       "      <td>392</td>\n",
       "      <td>85302</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>Mar</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19:52:15</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text place  \\\n",
       "0  Pretty much any corona virus germ that wants t...   NaN   \n",
       "1     RT @RealSaavedra: Good.\\n\\nIt came from China.   NaN   \n",
       "2        RT @nicolebyer: Everyone in this looks sick   NaN   \n",
       "3  RT @jabinbotsford: Close up of President @real...   NaN   \n",
       "4  RT @Biancaixvi: Corona day 3: it just feels li...   NaN   \n",
       "\n",
       "             user_location followers_count retweet_count favorite_count  \\\n",
       "0                PG County             478             0             10   \n",
       "1  Sydney, New South Wales             394           102              0   \n",
       "2                  ferrets             695         48499              0   \n",
       "3                      NaN              19         30492              0   \n",
       "4              Huntley, IL             392         85302              0   \n",
       "\n",
       "  weekday month   day      time  ...  num_present  trump_present  \\\n",
       "0     Thu   Mar  19.0  19:52:15  ...        False          False   \n",
       "1     Thu   Mar  19.0  19:52:15  ...        False          False   \n",
       "2     Thu   Mar  19.0  19:52:15  ...        False          False   \n",
       "3     Thu   Mar  19.0  19:52:15  ...        False           True   \n",
       "4     Thu   Mar  19.0  19:52:15  ...         True          False   \n",
       "\n",
       "   hashtag_present  covid  vaccine  profanity_present  emoji_present  \\\n",
       "0            False   True    False              False          False   \n",
       "1            False  False    False              False          False   \n",
       "2            False  False    False              False          False   \n",
       "3            False   True    False              False          False   \n",
       "4            False   True    False              False          False   \n",
       "\n",
       "   url_present  question_exclamation_present  sentiment  \n",
       "0         True                         False   positive  \n",
       "1        False                         False   positive  \n",
       "2        False                         False   negative  \n",
       "3        False                         False    neutral  \n",
       "4        False                         False    neutral  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the dataframes\n",
    "train_feats.head(5)\n",
    "#train_feats.columns                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                             object\n",
       "place                            object\n",
       "user_location                    object\n",
       "followers_count                  object\n",
       "retweet_count                    object\n",
       "favorite_count                   object\n",
       "weekday                          object\n",
       "month                            object\n",
       "day                             float64\n",
       "time                             object\n",
       "year                            float64\n",
       "num_present                        bool\n",
       "trump_present                      bool\n",
       "hashtag_present                    bool\n",
       "covid                              bool\n",
       "vaccine                            bool\n",
       "profanity_present                  bool\n",
       "emoji_present                      bool\n",
       "url_present                        bool\n",
       "question_exclamation_present       bool\n",
       "sentiment                        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature manipulation to make them ready for the model\n",
    "# Change sentiment labels to numbers!\n",
    "train_feats['sentiment'] = train_feats['sentiment'].astype('category')\n",
    "train_feats[\"sentiment\"] = train_feats[\"sentiment\"].cat.codes\n",
    "\n",
    "# Change location\n",
    "train_feats[\"user_location\"] = train_feats[\"user_location\"].astype('category')\n",
    "train_feats[\"user_location\"] = train_feats[\"user_location\"].cat.codes\n",
    "\n",
    "# Change place\n",
    "train_feats[\"place\"] = train_feats[\"place\"].astype('category')\n",
    "train_feats[\"place\"] = train_feats[\"place\"].cat.codes\n",
    "\n",
    "# Change weekday\n",
    "#train_feats[\"weekday\"] = train_feats[\"weekday\"].astype('category')\n",
    "#train_feats[\"weekday\"] = train_feats[\"weekday\"].cat.codes\n",
    "\n",
    "# Change month\n",
    "train_feats[\"month\"] = train_feats[\"month\"].astype('category')\n",
    "train_feats[\"month\"] = train_feats[\"month\"].cat.codes\n",
    "\n",
    "# Change time to datetime object\n",
    "#train_feats['time'] = train_feats['time'].apply(lambda x: datetime.datetime.strptime(str(x), '%H:%M:%S'))\n",
    "\n",
    "# Add hour and minute columns\n",
    "#train_feats['hour'] = train_feats['time'].apply(lambda x: x.hour)\n",
    "#train_feats['minute'] = train_feats['time'].apply(lambda x: x.minute)\n",
    "\n",
    "# Drop time\n",
    "train_feats = train_feats.drop(['time'], axis=1)\n",
    "\n",
    "# Change all the bool types to numeric\n",
    "train_feats[\"num_present\"] = train_feats[\"num_present\"].astype(int)\n",
    "train_feats[\"trump_present\"] = train_feats[\"trump_present\"].astype(int)\n",
    "#train_feats[\"hashtag_present\"] = train_feats[\"hashtag_present\"].astype(int)\n",
    "train_feats[\"covid\"] = train_feats[\"covid\"].astype(int)\n",
    "train_feats[\"vaccine\"] = train_feats[\"vaccine\"].astype(int)\n",
    "train_feats[\"profanity_present\"] = train_feats[\"profanity_present\"].astype(int)\n",
    "#train_feats[\"emoji_present\"] = train_feats[\"emoji_present\"].astype(int)\n",
    "train_feats[\"url_present\"] = train_feats[\"url_present\"].astype(int)\n",
    "#train_feats[\"question_exclamation_present\"] = train_feats[\"question_exclamation_present\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = train_feats['text'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=100, min_df=7, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "processed_features = vectorizer.fit_transform(all_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop text (JUST FOR A TEST)\n",
    "train_feats = train_feats.drop(['text'], axis=1)\n",
    "train_feats = train_feats.drop(['weekday'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sentiment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sentiment'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e65356f898c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get data ready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Get sentiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Drop labels from larger dataframee\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sentiment'"
     ]
    }
   ],
   "source": [
    "# Get data ready\n",
    "# Get sentiment\n",
    "labels = train_feats['sentiment']\n",
    "# Drop labels from larger dataframee\n",
    "train_feats = train_feats.drop(['sentiment'], axis=1)\n",
    "\n",
    "# Convert both to numpy arrays\n",
    "#non_text_feats = train_feats.to_numpy()\n",
    "#X = np.concatenate((processed_features, non_text_feats), axis=1)\n",
    "X = processed_features\n",
    "y = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model - Multinomial logistic regression\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# Train model\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6274510473219177\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X)\n",
    "# Print score\n",
    "print(accuracy_score(y_preds, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6274510473219177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y, y_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "db7d3e87e6340b482333b66fc9e1422c5abdf2e2aa02949130528e569bdc2c91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
