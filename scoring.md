You should give a formal definition of the evaluation metric that explains how it is calculated in a markdown file called scoring.md - this file should cite any relevant papers that introduce the metric. You can also cite Wikipedia articles that describe your evaluation metric
Your scoring.md file should also show how to run your evaluation script on the command line (with example arguments, and example output). The scoring.md file should say whether higher scores are better, or lower scores are better.

F1 Score or Accuracy most common:
https://www.sciencedirect.com/science/article/pii/S0925231217316090
https://arxiv.org/pdf/1908.10063.pdf
https://arxiv.org/pdf/2005.07503.pdf 